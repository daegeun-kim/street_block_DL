{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dfb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3694ba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_pickle(\"combined_with_graph.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e755401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ur20</th>\n",
       "      <th>area</th>\n",
       "      <th>isoperi</th>\n",
       "      <th>solidity</th>\n",
       "      <th>rectan</th>\n",
       "      <th>pop_den</th>\n",
       "      <th>geom</th>\n",
       "      <th>city</th>\n",
       "      <th>graph</th>\n",
       "      <th>urbanity</th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_nodes_norm</th>\n",
       "      <th>area_norm</th>\n",
       "      <th>graph_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U</td>\n",
       "      <td>16200.825</td>\n",
       "      <td>0.697</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.956</td>\n",
       "      <td>28616.003</td>\n",
       "      <td>0106000020E61000000100000001030000000100000005...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>[(x, [tensor([-2.7466e-04,  9.6512e-04,  1.655...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506076</td>\n",
       "      <td>-0.152350</td>\n",
       "      <td>[(x, [tensor([-0.0707,  0.3123, -1.9828,  2.63...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U</td>\n",
       "      <td>24292.633</td>\n",
       "      <td>0.609</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.949</td>\n",
       "      <td>8742.396</td>\n",
       "      <td>0106000020E61000000100000001030000000100000005...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>[(x, [tensor([-1.5259e-05,  1.3580e-03,  1.714...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506076</td>\n",
       "      <td>-0.134449</td>\n",
       "      <td>[(x, [tensor([-3.8756e-03,  4.3945e-01, -1.876...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U</td>\n",
       "      <td>19628.887</td>\n",
       "      <td>0.663</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.964</td>\n",
       "      <td>10555.762</td>\n",
       "      <td>0106000020E61000000100000001030000000100000005...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>[(x, [tensor([-2.5940e-04,  1.1253e-03,  1.655...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506076</td>\n",
       "      <td>-0.144766</td>\n",
       "      <td>[(x, [tensor([-0.0668,  0.3642, -1.9826,  3.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U</td>\n",
       "      <td>15393.900</td>\n",
       "      <td>0.561</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.979</td>\n",
       "      <td>7739.343</td>\n",
       "      <td>0106000020E61000000100000001030000000100000005...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>[(x, [tensor([-1.2131e-03,  2.6321e-04,  1.515...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506076</td>\n",
       "      <td>-0.154135</td>\n",
       "      <td>[(x, [tensor([-0.3126,  0.0852, -2.2310,  0.57...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U</td>\n",
       "      <td>14438.490</td>\n",
       "      <td>0.654</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.903</td>\n",
       "      <td>80365.333</td>\n",
       "      <td>0106000020E61000000100000001030000000100000005...</td>\n",
       "      <td>nyc</td>\n",
       "      <td>[(x, [tensor([-1.0147e-03, -4.5776e-04,  1.332...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.506076</td>\n",
       "      <td>-0.156248</td>\n",
       "      <td>[(x, [tensor([-0.2615, -0.1481, -2.5571,  0.81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746044</th>\n",
       "      <td>U</td>\n",
       "      <td>4523.137</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.911</td>\n",
       "      <td>37220.700</td>\n",
       "      <td>0106000020E61000000100000001030000000100000020...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>[(x, [tensor([-5.7983e-04,  8.7738e-05,  1.815...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.058077</td>\n",
       "      <td>-0.178184</td>\n",
       "      <td>[(x, [tensor([-0.1494,  0.0284, -1.6969, -0.64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746045</th>\n",
       "      <td>R</td>\n",
       "      <td>74509.144</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.606</td>\n",
       "      <td>1564.233</td>\n",
       "      <td>0106000020E6100000010000000103000000010000003A...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>[(x, [tensor([-1.9989e-03, -1.3390e-03,  1.195...</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.601335</td>\n",
       "      <td>-0.023357</td>\n",
       "      <td>[(x, [tensor([-0.5152, -0.4333, -2.8017, -0.40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746046</th>\n",
       "      <td>U</td>\n",
       "      <td>275861.703</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.549</td>\n",
       "      <td>2243.902</td>\n",
       "      <td>0106000020E61000000100000001030000000100000060...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>[(x, [tensor([-3.3340e-03, -2.4490e-03,  3.122...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1.395328</td>\n",
       "      <td>0.422084</td>\n",
       "      <td>[(x, [tensor([-0.8594, -0.7925,  0.6291, -0.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746047</th>\n",
       "      <td>U</td>\n",
       "      <td>93645.666</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.576</td>\n",
       "      <td>7826.994</td>\n",
       "      <td>0106000020E6100000010000000103000000010000002C...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>[(x, [tensor([-2.6779e-03,  9.9945e-04,  1.550...</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0.308811</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>[(x, [tensor([-0.6903,  0.3234, -2.1692, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746048</th>\n",
       "      <td>U</td>\n",
       "      <td>341537.494</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.460</td>\n",
       "      <td>4330.069</td>\n",
       "      <td>0106000020E61000000100000001030000000100000091...</td>\n",
       "      <td>seattle</td>\n",
       "      <td>[(x, [tensor([-8.9264e-03,  2.7695e-03,  1.570...</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>2.419161</td>\n",
       "      <td>0.567375</td>\n",
       "      <td>[(x, [tensor([-2.3010,  0.8962, -2.1329, -0.31...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746049 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ur20        area  isoperi  solidity  rectan    pop_den  \\\n",
       "0         U   16200.825    0.697     1.000   0.956  28616.003   \n",
       "1         U   24292.633    0.609     1.000   0.949   8742.396   \n",
       "2         U   19628.887    0.663     1.000   0.964  10555.762   \n",
       "3         U   15393.900    0.561     1.000   0.979   7739.343   \n",
       "4         U   14438.490    0.654     1.000   0.903  80365.333   \n",
       "...     ...         ...      ...       ...     ...        ...   \n",
       "746044    U    4523.137    0.570     0.992   0.911  37220.700   \n",
       "746045    R   74509.144    0.545     0.808   0.606   1564.233   \n",
       "746046    U  275861.703    0.427     0.720   0.549   2243.902   \n",
       "746047    U   93645.666    0.440     0.794   0.576   7826.994   \n",
       "746048    U  341537.494    0.366     0.765   0.460   4330.069   \n",
       "\n",
       "                                                     geom     city  \\\n",
       "0       0106000020E61000000100000001030000000100000005...      nyc   \n",
       "1       0106000020E61000000100000001030000000100000005...      nyc   \n",
       "2       0106000020E61000000100000001030000000100000005...      nyc   \n",
       "3       0106000020E61000000100000001030000000100000005...      nyc   \n",
       "4       0106000020E61000000100000001030000000100000005...      nyc   \n",
       "...                                                   ...      ...   \n",
       "746044  0106000020E61000000100000001030000000100000020...  seattle   \n",
       "746045  0106000020E6100000010000000103000000010000003A...  seattle   \n",
       "746046  0106000020E61000000100000001030000000100000060...  seattle   \n",
       "746047  0106000020E6100000010000000103000000010000002C...  seattle   \n",
       "746048  0106000020E61000000100000001030000000100000091...  seattle   \n",
       "\n",
       "                                                    graph  urbanity  \\\n",
       "0       [(x, [tensor([-2.7466e-04,  9.6512e-04,  1.655...         1   \n",
       "1       [(x, [tensor([-1.5259e-05,  1.3580e-03,  1.714...         1   \n",
       "2       [(x, [tensor([-2.5940e-04,  1.1253e-03,  1.655...         1   \n",
       "3       [(x, [tensor([-1.2131e-03,  2.6321e-04,  1.515...         1   \n",
       "4       [(x, [tensor([-1.0147e-03, -4.5776e-04,  1.332...         1   \n",
       "...                                                   ...       ...   \n",
       "746044  [(x, [tensor([-5.7983e-04,  8.7738e-05,  1.815...         1   \n",
       "746045  [(x, [tensor([-1.9989e-03, -1.3390e-03,  1.195...         0   \n",
       "746046  [(x, [tensor([-3.3340e-03, -2.4490e-03,  3.122...         1   \n",
       "746047  [(x, [tensor([-2.6779e-03,  9.9945e-04,  1.550...         1   \n",
       "746048  [(x, [tensor([-8.9264e-03,  2.7695e-03,  1.570...         1   \n",
       "\n",
       "        num_nodes  num_nodes_norm  area_norm  \\\n",
       "0               4       -0.506076  -0.152350   \n",
       "1               4       -0.506076  -0.134449   \n",
       "2               4       -0.506076  -0.144766   \n",
       "3               4       -0.506076  -0.154135   \n",
       "4               4       -0.506076  -0.156248   \n",
       "...           ...             ...        ...   \n",
       "746044         31        0.058077  -0.178184   \n",
       "746045         57        0.601335  -0.023357   \n",
       "746046         95        1.395328   0.422084   \n",
       "746047         43        0.308811   0.018977   \n",
       "746048        144        2.419161   0.567375   \n",
       "\n",
       "                                               graph_norm  \n",
       "0       [(x, [tensor([-0.0707,  0.3123, -1.9828,  2.63...  \n",
       "1       [(x, [tensor([-3.8756e-03,  4.3945e-01, -1.876...  \n",
       "2       [(x, [tensor([-0.0668,  0.3642, -1.9826,  3.21...  \n",
       "3       [(x, [tensor([-0.3126,  0.0852, -2.2310,  0.57...  \n",
       "4       [(x, [tensor([-0.2615, -0.1481, -2.5571,  0.81...  \n",
       "...                                                   ...  \n",
       "746044  [(x, [tensor([-0.1494,  0.0284, -1.6969, -0.64...  \n",
       "746045  [(x, [tensor([-0.5152, -0.4333, -2.8017, -0.40...  \n",
       "746046  [(x, [tensor([-0.8594, -0.7925,  0.6291, -0.42...  \n",
       "746047  [(x, [tensor([-0.6903,  0.3234, -2.1692, -0.01...  \n",
       "746048  [(x, [tensor([-2.3010,  0.8962, -2.1329, -0.31...  \n",
       "\n",
       "[746049 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['urbanity'] = (combined['ur20'] == 'U').astype(int)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189bff43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urbanity\n",
       "1    721822\n",
       "0     24227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['urbanity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf660ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42214088757.678"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['area'].loc[combined['urbanity']==1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4335db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21250287587.681004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['area'].loc[combined['urbanity']==0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80db978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from shapely import wkb, wkt\n",
    "from shapely.geometry import Polygon, MultiPolygon,LinearRing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c89ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"num_nodes\"] = combined[\"graph\"].apply(lambda g: g.num_nodes)\n",
    "combined[\"num_nodes_norm\"] = (combined[\"num_nodes\"] - combined[\"num_nodes\"].mean()) / combined[\"num_nodes\"].std()\n",
    "combined[\"area_norm\"] = (combined[\"area\"] - combined[\"area\"].mean()) / combined[\"area\"].std()\n",
    "\n",
    "all_x = torch.cat([g.x for g in combined[\"graph\"]], dim=0)\n",
    "x_mean = all_x.mean(dim=0)\n",
    "x_std = all_x.std(dim=0)\n",
    "def normalize_graph(g):\n",
    "    g = g.clone()\n",
    "    g.x = (g.x - x_mean) / x_std\n",
    "    return g\n",
    "\n",
    "combined[\"graph_norm\"] = combined[\"graph\"].apply(normalize_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c9e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combined.loc[combined['city']!='houston'] # hold-out a generic city for validation set\n",
    "val = combined.loc[combined['city']=='houston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f777901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch\n",
    "\n",
    "class GraphOnlyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.target_col = \"urbanity\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        g = row[\"graph_norm\"].clone()\n",
    "        g.y = torch.tensor([float(row[self.target_col])], dtype=torch.float32)\n",
    "\n",
    "        area_feat = torch.tensor([float(row[\"area_norm\"])], dtype=torch.float32)\n",
    "        num_nodes_feat = torch.tensor([float(row[\"num_nodes_norm\"])], dtype=torch.float32)\n",
    "        g.graph_feat = torch.cat([area_feat, num_nodes_feat], dim=0)\n",
    "\n",
    "        g.area_w = torch.tensor([float(row[\"area\"])], dtype=torch.float32)\n",
    "        return g\n",
    "\n",
    "train_dataset = GraphOnlyDataset(train)\n",
    "val_dataset = GraphOnlyDataset(val)\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "BATCH_SIZE = 8192\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a84c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1524 38.706\n",
      "6 3048 77.412\n"
     ]
    }
   ],
   "source": [
    "nodes = []\n",
    "edges = []\n",
    "for i in range(1000):\n",
    "    g = train_dataset[i]\n",
    "    nodes.append(g.num_nodes)\n",
    "    edges.append(g.edge_index.size(1))\n",
    "\n",
    "print(min(nodes), max(nodes), sum(nodes)/len(nodes))\n",
    "print(min(edges), max(edges), sum(edges)/len(edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fc91c",
   "metadata": {},
   "source": [
    "# Graph Training Model\n",
    "Iteration 1:\n",
    "- GCNConv\n",
    "- ReLu\n",
    "- hidden layer width: 64, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2240b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, global_mean_pool, GraphNorm\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def get_activation(name: str):\n",
    "    name = name.lower()\n",
    "    if name == \"relu\":\n",
    "        return F.relu\n",
    "    if name == \"sigmoid\":\n",
    "        return torch.sigmoid\n",
    "    if name == \"tanh\":\n",
    "        return torch.tanh\n",
    "    if name == \"gelu\":\n",
    "        return F.gelu\n",
    "    if name == \"leaky_relu\":\n",
    "        return F.leaky_relu\n",
    "    raise ValueError(f\"Unknown activation: {name}\")\n",
    "\n",
    "def get_conv(name: str):\n",
    "    name = name.lower()\n",
    "    if name == \"gcn\":\n",
    "        return GCNConv\n",
    "    if name == \"sage\":\n",
    "        return SAGEConv\n",
    "    raise ValueError(f\"Unknown conv: {name}\")\n",
    "\n",
    "class GraphClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_in_dim: int,\n",
    "        conv_type: str = \"gcn\",\n",
    "        gnn_hidden: int = 64,\n",
    "        use_graphnorm: bool = False,\n",
    "        activation: str = \"relu\",\n",
    "        use_feat: bool = True,\n",
    "        feat_dim: int = 2,\n",
    "        mlp_hidden1: int = 64,\n",
    "        mlp_hidden2: int = 32,\n",
    "        mlp_hidden3: int = 32,\n",
    "        dropout_p: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_feat = use_feat\n",
    "        self.feat_dim = feat_dim if use_feat else 0\n",
    "        self.act = get_activation(activation)\n",
    "        self.dropout_p = dropout_p\n",
    "\n",
    "        Conv = get_conv(conv_type)\n",
    "        self.conv1 = Conv(node_in_dim, gnn_hidden)\n",
    "        self.conv2 = Conv(gnn_hidden, gnn_hidden)\n",
    "        self.conv3 = Conv(gnn_hidden, gnn_hidden)\n",
    "\n",
    "        self.use_graphnorm = use_graphnorm\n",
    "        if use_graphnorm:\n",
    "            self.norm1 = GraphNorm(gnn_hidden)\n",
    "            self.norm2 = GraphNorm(gnn_hidden)\n",
    "            self.norm3 = GraphNorm(gnn_hidden)\n",
    "\n",
    "        self.fc1 = nn.Linear(gnn_hidden + self.feat_dim, mlp_hidden1)\n",
    "        self.fc2 = nn.Linear(mlp_hidden1, mlp_hidden2)\n",
    "        self.fc3 = nn.Linear(mlp_hidden2, mlp_hidden3)\n",
    "        self.fc4 = nn.Linear(mlp_hidden3, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = self.conv1(batch.x, batch.edge_index)\n",
    "        if self.use_graphnorm:\n",
    "            x = self.norm1(x, batch.batch)\n",
    "        x = self.act(x)\n",
    "        x = F.dropout(x, p=self.dropout_p, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, batch.edge_index)\n",
    "        if self.use_graphnorm:\n",
    "            x = self.norm2(x, batch.batch)\n",
    "        x = self.act(x)\n",
    "        x = F.dropout(x, p=self.dropout_p, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, batch.edge_index)\n",
    "        if self.use_graphnorm:\n",
    "            x = self.norm3(x, batch.batch)\n",
    "        x = self.act(x)\n",
    "        x = F.dropout(x, p=self.dropout_p, training=self.training)\n",
    "\n",
    "        g = global_mean_pool(x, batch.batch)\n",
    "\n",
    "        if self.use_feat:\n",
    "            gf = batch.graph_feat\n",
    "            if gf.dim() == 1:\n",
    "                gf = gf.view(g.size(0), -1)\n",
    "            z = torch.cat([g, gf], dim=1)\n",
    "        else:\n",
    "            z = g\n",
    "\n",
    "        h = self.act(self.fc1(z))\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        h = self.act(self.fc2(h))\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        h = self.act(self.fc3(h))\n",
    "        h = F.dropout(h, p=self.dropout_p, training=self.training)\n",
    "        return self.fc4(h)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "node_in_dim = train_dataset[0].x.size(1)\n",
    "\n",
    "def run(\n",
    "    use_feat: bool,\n",
    "    conv_type: str = \"gcn\",\n",
    "    use_graphnorm: bool = False,\n",
    "    activation: str = \"relu\",\n",
    "    gnn_hidden: int = 64,\n",
    "    mlp_hidden1: int = 64,\n",
    "    mlp_hidden2: int = 32,\n",
    "    dropout_p: float = 0.0,\n",
    "    epochs: int = 5,\n",
    "    lr: float = 0.001,\n",
    "    col_name: str = \"y_pred\",\n",
    "    pred_df=None,\n",
    "    pred_batch_size: int = 2048,\n",
    "):\n",
    "    model = GraphClassifier(\n",
    "        node_in_dim=node_in_dim,\n",
    "        conv_type=conv_type,\n",
    "        gnn_hidden=gnn_hidden,\n",
    "        use_graphnorm=use_graphnorm,\n",
    "        activation=activation,\n",
    "        use_feat=use_feat,\n",
    "        feat_dim=2,\n",
    "        mlp_hidden1=mlp_hidden1,\n",
    "        mlp_hidden2=mlp_hidden2,\n",
    "        dropout_p=dropout_p,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            logits = model(batch)\n",
    "            yb = batch.y.view(-1, 1)\n",
    "\n",
    "            w = torch.log1p(batch.area_w.view(-1, 1))\n",
    "            loss_vec = F.binary_cross_entropy_with_logits(logits, yb, reduction=\"none\")\n",
    "            loss = (loss_vec * w).sum() / (w.sum() + 1e-8)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        total_w = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device, non_blocking=True)\n",
    "                logits = model(batch)\n",
    "                yb = batch.y.view(-1, 1)\n",
    "\n",
    "                w = torch.log1p(batch.area_w.view(-1, 1))\n",
    "                loss_vec = F.binary_cross_entropy_with_logits(logits, yb, reduction=\"none\")\n",
    "                total_loss += (loss_vec * w).sum().item()\n",
    "                total_w += w.sum().item()\n",
    "\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                correct += (preds == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "\n",
    "        avg_loss = total_loss / (total_w + 1e-8)\n",
    "        error_rate = 1.0 - (correct / total)\n",
    "        print(f\"Epoch {epoch+1}: val_loss = {avg_loss:.4f}, val_error = {error_rate:.4f}\")\n",
    "\n",
    "    if pred_df is None:\n",
    "        pred_df = combined\n",
    "\n",
    "    pred_dataset = GraphOnlyDataset(pred_df)\n",
    "    pred_loader = DataLoader(\n",
    "        pred_dataset,\n",
    "        batch_size=pred_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in pred_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            logits = model(batch)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).int()\n",
    "            y_pred.extend(preds.view(-1).cpu().tolist())\n",
    "\n",
    "    pred_df[col_name] = y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39aa9db",
   "metadata": {},
   "source": [
    "# Initial 5 epoch testing & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c4da712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val_loss = 0.1678, val_error = 0.0385\n",
      "Epoch 2: val_loss = 0.1578, val_error = 0.0385\n",
      "Epoch 3: val_loss = 0.1443, val_error = 0.0385\n",
      "Epoch 4: val_loss = 0.1362, val_error = 0.0367\n",
      "Epoch 5: val_loss = 0.1244, val_error = 0.0342\n"
     ]
    }
   ],
   "source": [
    "run(\n",
    "  use_feat=False, \n",
    "  conv_type=\"sage\", \n",
    "  use_graphnorm=True, \n",
    "  activation=\"relu\", \n",
    "  gnn_hidden=128, \n",
    "  mlp_hidden1=64, \n",
    "  mlp_hidden2=32, \n",
    "  epochs=5, \n",
    "  col_name=\"y_pred_1\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb4d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val_loss = 0.1694, val_error = 0.0385\n",
      "Epoch 2: val_loss = 0.1486, val_error = 0.0379\n",
      "Epoch 3: val_loss = 0.1287, val_error = 0.0344\n",
      "Epoch 4: val_loss = 0.1236, val_error = 0.0331\n",
      "Epoch 5: val_loss = 0.1208, val_error = 0.0328\n"
     ]
    }
   ],
   "source": [
    "run(\n",
    "  use_feat=False, \n",
    "  conv_type=\"sage\", \n",
    "  use_graphnorm=True, \n",
    "  activation=\"relu\", \n",
    "  gnn_hidden=64, \n",
    "  mlp_hidden1=128, \n",
    "  mlp_hidden2=256, \n",
    "  epochs=5, \n",
    "  col_name=\"y_pred_2\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e577baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val_loss = 0.1600, val_error = 0.0385\n",
      "Epoch 2: val_loss = 0.1328, val_error = 0.0351\n",
      "Epoch 3: val_loss = 0.1236, val_error = 0.0334\n",
      "Epoch 4: val_loss = 0.1275, val_error = 0.0334\n",
      "Epoch 5: val_loss = 0.1194, val_error = 0.0323\n"
     ]
    }
   ],
   "source": [
    "run(\n",
    "  use_feat=False, \n",
    "  conv_type=\"sage\", \n",
    "  use_graphnorm=True, \n",
    "  activation=\"relu\", \n",
    "  gnn_hidden=64, \n",
    "  mlp_hidden1=128, \n",
    "  mlp_hidden2=256, \n",
    "  epochs=5, \n",
    "  col_name=\"y_pred_3\",\n",
    "  lr=0.003,\n",
    "  dropout_p=0.1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3983d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: val_loss = 0.1501, val_error = 0.0385\n",
      "Epoch 2: val_loss = 0.1293, val_error = 0.0343\n",
      "Epoch 3: val_loss = 0.1197, val_error = 0.0327\n",
      "Epoch 4: val_loss = 0.1188, val_error = 0.0324\n",
      "Epoch 5: val_loss = 0.1191, val_error = 0.0322\n"
     ]
    }
   ],
   "source": [
    "run(\n",
    "  use_feat=False, \n",
    "  conv_type=\"sage\", \n",
    "  use_graphnorm=True, \n",
    "  activation=\"relu\", \n",
    "  gnn_hidden=64, \n",
    "  mlp_hidden1=128, \n",
    "  mlp_hidden2=256, \n",
    "  epochs=5, \n",
    "  col_name=\"y_pred_4\",\n",
    "  lr=0.005,\n",
    "  dropout_p=0.1\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7390b49",
   "metadata": {},
   "source": [
    "Pause and Continue Epoch Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a05cf31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_run(\n",
    "    use_feat: bool,\n",
    "    conv_type: str = \"gcn\",\n",
    "    use_graphnorm: bool = False,\n",
    "    activation: str = \"relu\",\n",
    "    gnn_hidden: int = 64,\n",
    "    mlp_hidden1: int = 64,\n",
    "    mlp_hidden2: int = 32,\n",
    "    mlp_hidden3: int = 32,\n",
    "    dropout_p: float = 0.0,\n",
    "    epochs: int = 5,\n",
    "    lr: float = 0.001,\n",
    "    col_name: str = \"y_pred\",\n",
    "    pred_df=None,\n",
    "    pred_batch_size: int = 2048,\n",
    "    ckpt_path: str = \"checkpoint.pt\",\n",
    "    history_df: pd.DataFrame | None = None,\n",
    "    history_path: str = \"history.csv\",\n",
    "    iter_name: str = \"iter1\",\n",
    "):\n",
    "    loss_col = f\"{iter_name}_loss\"\n",
    "    err_col = f\"{iter_name}_error\"\n",
    "\n",
    "    if history_df is None:\n",
    "        history_df = pd.DataFrame({\"epoch\": list(range(1, epochs + 1))})\n",
    "        history_df.set_index(\"epoch\", inplace=True)\n",
    "    else:\n",
    "        if history_df.index.name != \"epoch\":\n",
    "            if \"epoch\" in history_df.columns:\n",
    "                history_df = history_df.set_index(\"epoch\")\n",
    "            else:\n",
    "                history_df.index.name = \"epoch\"\n",
    "        if len(history_df.index) < epochs:\n",
    "            new_idx = list(range(len(history_df.index) + 1, epochs + 1))\n",
    "            history_df = pd.concat([history_df, pd.DataFrame(index=new_idx)], axis=0)\n",
    "        history_df = history_df.sort_index()\n",
    "\n",
    "    model = GraphClassifier(\n",
    "        node_in_dim=node_in_dim,\n",
    "        conv_type=conv_type,\n",
    "        gnn_hidden=gnn_hidden,\n",
    "        use_graphnorm=use_graphnorm,\n",
    "        activation=activation,\n",
    "        use_feat=use_feat,\n",
    "        feat_dim=2,\n",
    "        mlp_hidden1=mlp_hidden1,\n",
    "        mlp_hidden2=mlp_hidden2,\n",
    "        mlp_hidden3=mlp_hidden3,\n",
    "        dropout_p=dropout_p,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    start_epoch = 0\n",
    "    if os.path.exists(ckpt_path):\n",
    "        ckpt = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(ckpt[\"model_state\"])\n",
    "        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n",
    "        start_epoch = ckpt[\"epoch\"]\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            logits = model(batch)\n",
    "            yb = batch.y.view(-1, 1)\n",
    "\n",
    "            w = torch.log1p(batch.area_w.view(-1, 1))\n",
    "            loss_vec = F.binary_cross_entropy_with_logits(logits, yb, reduction=\"none\")\n",
    "            loss = (loss_vec * w).sum() / (w.sum() + 1e-8)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        total_w = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device, non_blocking=True)\n",
    "                logits = model(batch)\n",
    "                yb = batch.y.view(-1, 1)\n",
    "\n",
    "                w = torch.log1p(batch.area_w.view(-1, 1))\n",
    "                loss_vec = F.binary_cross_entropy_with_logits(logits, yb, reduction=\"none\")\n",
    "                total_loss += (loss_vec * w).sum().item()\n",
    "                total_w += w.sum().item()\n",
    "\n",
    "                preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "                correct += (preds == yb).sum().item()\n",
    "                total += yb.size(0)\n",
    "\n",
    "        avg_loss = total_loss / (total_w + 1e-8)\n",
    "        error_rate = 1.0 - (correct / total)\n",
    "\n",
    "        history_df.loc[epoch + 1, loss_col] = avg_loss\n",
    "        history_df.loc[epoch + 1, err_col] = error_rate\n",
    "        history_df.to_csv(history_path)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: val_loss = {avg_loss:.4f}, val_error = {error_rate:.4f}\")\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"config\": {\n",
    "                    \"use_feat\": use_feat,\n",
    "                    \"conv_type\": conv_type,\n",
    "                    \"use_graphnorm\": use_graphnorm,\n",
    "                    \"activation\": activation,\n",
    "                    \"gnn_hidden\": gnn_hidden,\n",
    "                    \"mlp_hidden1\": mlp_hidden1,\n",
    "                    \"mlp_hidden2\": mlp_hidden2,\n",
    "                    \"mlp_hidden3\": mlp_hidden3,\n",
    "                    \"dropout_p\": dropout_p,\n",
    "                    \"lr\": lr,\n",
    "                },\n",
    "            },\n",
    "            ckpt_path,\n",
    "        )\n",
    "\n",
    "    if pred_df is None:\n",
    "        pred_df = combined\n",
    "\n",
    "    pred_dataset = GraphOnlyDataset(pred_df)\n",
    "    pred_loader = DataLoader(\n",
    "        pred_dataset,\n",
    "        batch_size=pred_batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch in pred_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            logits = model(batch)\n",
    "            preds = (torch.sigmoid(logits) >= 0.5).int()\n",
    "            y_pred.extend(preds.view(-1).cpu().tolist())\n",
    "\n",
    "    pred_df[col_name] = y_pred\n",
    "\n",
    "    return model, history_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5139d",
   "metadata": {},
   "source": [
    "# Final Iterations\n",
    "Iteration 1: lr:0.005, 64-128-256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a6e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: val_loss = 0.1171, val_error = 0.0320\n",
      "Epoch 32: val_loss = 0.1166, val_error = 0.0325\n",
      "Epoch 33: val_loss = 0.1177, val_error = 0.0323\n",
      "Epoch 34: val_loss = 0.1187, val_error = 0.0325\n",
      "Epoch 35: val_loss = 0.1186, val_error = 0.0321\n",
      "Epoch 36: val_loss = 0.1169, val_error = 0.0319\n",
      "Epoch 37: val_loss = 0.1192, val_error = 0.0321\n",
      "Epoch 38: val_loss = 0.1155, val_error = 0.0323\n",
      "Epoch 39: val_loss = 0.1170, val_error = 0.0324\n",
      "Epoch 40: val_loss = 0.1174, val_error = 0.0322\n",
      "Epoch 41: val_loss = 0.1198, val_error = 0.0335\n",
      "Epoch 42: val_loss = 0.1179, val_error = 0.0324\n",
      "Epoch 43: val_loss = 0.1161, val_error = 0.0323\n",
      "Epoch 44: val_loss = 0.1161, val_error = 0.0321\n",
      "Epoch 45: val_loss = 0.1162, val_error = 0.0323\n",
      "Epoch 46: val_loss = 0.1200, val_error = 0.0328\n",
      "Epoch 47: val_loss = 0.1165, val_error = 0.0321\n",
      "Epoch 48: val_loss = 0.1165, val_error = 0.0323\n",
      "Epoch 49: val_loss = 0.1215, val_error = 0.0341\n",
      "Epoch 50: val_loss = 0.1246, val_error = 0.0321\n"
     ]
    }
   ],
   "source": [
    "hist = pd.read_csv(\"hist_iter1.csv\")\n",
    "\n",
    "model, hist = save_run(    # epoch:50\n",
    "    use_feat=False,\n",
    "    conv_type=\"sage\",\n",
    "    use_graphnorm=True,\n",
    "    activation=\"relu\",\n",
    "    gnn_hidden=64,\n",
    "    mlp_hidden1=128,\n",
    "    mlp_hidden2=256,\n",
    "    epochs=50,\n",
    "    lr=0.005,\n",
    "    dropout_p=0.1,\n",
    "    col_name=\"iter1\",\n",
    "    ckpt_path=\"ckpt_iter1.pt\",\n",
    "    iter_name=\"iter1\",\n",
    "    history_df=hist,\n",
    "    history_path=\"hist_iter1.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f7477bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: val_loss = 0.1281, val_error = 0.0356\n",
      "Epoch 42: val_loss = 0.1207, val_error = 0.0327\n",
      "Epoch 43: val_loss = 0.1183, val_error = 0.0326\n",
      "Epoch 44: val_loss = 0.1244, val_error = 0.0333\n",
      "Epoch 45: val_loss = 0.1193, val_error = 0.0325\n",
      "Epoch 46: val_loss = 0.1222, val_error = 0.0329\n",
      "Epoch 47: val_loss = 0.1176, val_error = 0.0323\n",
      "Epoch 48: val_loss = 0.1291, val_error = 0.0369\n",
      "Epoch 49: val_loss = 0.1229, val_error = 0.0326\n",
      "Epoch 50: val_loss = 0.1298, val_error = 0.0333\n"
     ]
    }
   ],
   "source": [
    "# hist = pd.read_csv(\"hist_iter2.csv\")\n",
    "\n",
    "model, hist = save_run(    # epoch:50\n",
    "    use_feat=False,\n",
    "    conv_type=\"sage\",\n",
    "    use_graphnorm=True,\n",
    "    activation=\"relu\",\n",
    "    gnn_hidden=128,\n",
    "    mlp_hidden1=128,\n",
    "    mlp_hidden2=128,\n",
    "    mlp_hidden3=128,\n",
    "    epochs=50,\n",
    "    lr=0.003,\n",
    "    dropout_p=0.1,\n",
    "    col_name=\"iter2\",\n",
    "    ckpt_path=\"ckpt_iter2.pt\",\n",
    "    iter_name=\"iter2\",\n",
    "    history_df=hist,\n",
    "    history_path=\"hist_iter2.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23e4550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9064,  15163],\n",
       "       [  5449, 716373]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(combined['urbanity'], combined['iter1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78749e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4702,  19525],\n",
       "       [   632, 721190]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(combined['urbanity'], combined['iter2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "12689fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iter1\n",
       "1    731536\n",
       "0     14513\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['iter1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48f82532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "urbanity\n",
       "1    721822\n",
       "0     24227\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['urbanity'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
